# Optimize ML Models and Deploy Human-in-the-Loop Pipelines

Visit: [Jseluis.com](https://jseluis.com)

### My Project from Practical Data Science Specialization, Coursera.

[My Certificate](https://www.coursera.org/account/accomplishments/specialization/certificate/BT2K6GVW7FPL)

[Optimize ML Models and Deploy Human-in-the-Loop Pipelines Certificate](https://www.coursera.org/account/accomplishments/certificate/RN8CLW4W3UJK)

- Project 1 - Optimize models using Automatic Model Tuning

    When training ML models, hyperparameter tuning is a step taken to find the best performing training model. In this lab you will apply a random algorithm of Automated Hyperparameter Tuning to train a BERT-based natural language processing (NLP) classifier. The model analyzes customer feedback and classifies the messages into positive (1), neutral (0), and negative (-1) sentiments.

    1. Configure dataset

    2. Configure and run hyper-parameter tuning job

    3. Evaluate the results

- Project 2 A/B testing, traffic shifting and autoscaling

    Create an endpoint with multiple variants, splitting the traffic between them. Then after testing and reviewing the endpoint performance metrics, you will shift the traffic to one variant and configure it to autoscale.

    4. Configure and create REST Enpoint with multiple variants

    5. Test the model

    6. Show the metrics for each variant

    7. Shift all traffic to one variant

    8. Configure one variant to autoscale

- Project 3 Data labeling and human-in-the-loop pipelines with Amazon Augmented AI (A2I)

    9. Setup private workforce and Cognito pool

    10. Create the Human Task UI using a Worker Task Template

    11. Create a Flow Definition

    12. Start and check the status of human loop

    13. Verify the completion

    14. View the labels and prepare data for training


### References: 

Advanced model training, tuning, and evaluation:

[Hyperband](https://arxiv.org/pdf/1603.06560.pdf) 

[Bayesian Optimization](https://arxiv.org/pdf/1206.2944.pdf)

[Amazon SageMaker Automatic Model Tuning](https://arxiv.org/pdf/2012.08489.pdf)

Advanced model deployment, and monitoring:

[A/B Testing](https://docs.aws.amazon.com/sagemaker/latest/dg/model-ab-testing.html)

[Autoscaling](https://docs.aws.amazon.com/sagemaker/latest/dg/endpoint-auto-scaling.html)

[Multi-armed bandit](https://aws.amazon.com/blogs/machine-learning/dynamic-a-b-testing-for-machine-learning-models-with-amazon-sagemaker-mlops-projects/)

[Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)

[Inference Pipeline](https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipelines.html)

[Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html)

Data labeling and human-in-the-loop pipelines:

[Towards Automated Data Quality Management for Machine Learning](https://assets.amazon.science/4a/75/57047bd343fabc46ec14b34cdb3b/towards-automated-data-quality-management-for-machine-learning.pdf)

[Amazon SageMaker Ground Truth Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html)

[Create high-quality instructions for Amazon SageMaker Ground Truth labeling jobs](https://aws.amazon.com/blogs/machine-learning/create-high-quality-instructions-for-amazon-sagemaker-ground-truth-labeling-jobs/)

[Amazon SageMaker Augmented AI (Amazon A2I) Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/a2i-getting-started.html)

[Amazon Augmented AI Sample Task UIs](https://github.com/aws-samples/amazon-a2i-sample-task-uis)

[Liquid open source Template Language](https://shopify.github.io/liquid/)